# BLACK_BOX
Репозиторий для задания INT14 PTStart

Автор: Гришин Александр grishin.alieksandr@inbox.ru

Данный репозиторий содержит 2 файла:
1) wiki_crawler.py - файл, содержащий python код, который осуществляет обход всех страниц и добавление всех ссылок википедии в базу данных SQLite
2) test_wiki_crawler.py - файл, содержащий юнит тесты на функции из предыдущего файла

Далее приведена инструкция по запуску тестов и обхода через файл wiki_crawler.py. Инструкция работает на Ubuntu 24.04

Для запуска тестов необходимо:

1) Установить все необходимые пакеты:
     ```bash
   apt install -y python3
     ```
2) Запустить тесты
     ```bash
   python3 -m unittest test_wiki_crawler.py
     ```

Для работы с файлом:

1) Для вывода информационного сообщения по работе с файлом:
     ```bash
   python3 wiki_crawler.py -h
     ```
     или
     ```bash
   python3 wiki_crawler.py --help
     ```

2) Для запуска файлы в режиме обхода всех страниц
     ```bash
   python3 wiki_crawler.py [--db DB] [--depth DEPTH] url
     ```
     где
     ```bash
   --db DB - Название базы данных
   --depth DEPTH - Глубина поиска
   url - стартовая URL с википедии
     ```

Данную программу можно запускать с разной глубиной поиска, где 
```bash
глубина = 0 - в базу сохранится только стартовая url,
глубина = 1 - в базу сохранится стартовая url и ссылки, которые находятся на стартовой url,
глубина = 2-  в базу сохранится стартовая url, ссылки, которые находятся на стартовой url, и ссылки, которые находятся на предыдущих ссылках,
и т.д.
 ```
